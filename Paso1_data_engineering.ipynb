{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0)See raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw(path):\n",
    "    file = path + 'C02Preci.csv'\n",
    "    Pp = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (mm)'], dtype={'Valor (mm)': float})#, na_values=[''])\n",
    "\n",
    "    file = path + 'C02Dviento.csv'\n",
    "    Dv = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (°)'], dtype={'Valor (°)': float})#, na_values=[''])\n",
    "    \n",
    "    file = path + 'C02Humedad.csv'\n",
    "    Hr = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (%)'], dtype={'Valor (%)': float})#, na_values=[''])\n",
    "\n",
    "    file = path + 'C02Presion.csv'\n",
    "    Ps = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (hPa)'], dtype={'Valor (hPa)': float})#, na_values=[''])\n",
    "\n",
    "    file = path + 'C02RSolar.csv'\n",
    "    Rs = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (W/m2)'], dtype={'Valor (W/m2)': float})#, na_values=[''])\n",
    "\n",
    "    file = path + 'C02Temperatura.csv'\n",
    "    T = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (°C)'], dtype={'Valor (°C)': float})#, na_values=[''])\n",
    "\n",
    "    file = path + 'C02Vviento.csv'\n",
    "    Vv = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (m/s)'], dtype={'Valor (m/s)': float})#, na_values=[''])\n",
    "\n",
    "    Dataset_r = pd.concat([Dv, Hr, Ps, Rs, T,Vv, Pp], axis=1)\n",
    "    \n",
    "    return (Dataset_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/juan/Desktop/TESIS/Codes/data/Rumihurco2021/'\n",
    "raw = read_raw(path)\n",
    "#np.round(raw.describe(),1).to_csv(path+'Rumihurco_describe_raw.csv')\n",
    "(np.round(raw.describe(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/juan/Desktop/TESIS/Codes/data/Rumipamba2021/'\n",
    "raw = read_raw(path)\n",
    "#np.round(raw.describe(),1).to_csv(path+'Rumipamba_describe_raw.csv')\n",
    "np.round(raw.describe(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Leer los datos, hacer preprocesamiento (sin data-scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data):\n",
    "    primer_valor = data.iloc[[0]]\n",
    "    while bool(primer_valor.isnull().values):\n",
    "        data = data.drop(primer_valor.index,axis=0)\n",
    "        primer_valor = data.iloc[[0]]\n",
    "    data = data.interpolate()\n",
    "    return(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fuction calls the csv file of each climate feature\n",
    "# reads only whats inside usecols=[\"...\"] \n",
    "# dtype cast the values\n",
    "# na_values indicates what are the null values expected to be\n",
    "# for each feature: reads, remove duplicates, linear interpolate \n",
    "# return the Dataset as a whole\n",
    "\n",
    "\n",
    "def read_csv(path):\n",
    "    file = path + 'C02Preci.csv'\n",
    "    Pp = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (mm)'], dtype={'Valor (mm)': float}, na_values=[''])\n",
    "    Pp = Pp.loc[~Pp.index.duplicated(keep='last')]\n",
    "    Pp = interpolate(Pp)\n",
    "    print(\"Preci.csv index are unique:\",Pp.index.is_unique)\n",
    "\n",
    "    file = path + 'C02Dviento.csv'\n",
    "    Dv = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (°)'], dtype={'Valor (°)': float}, na_values=[''])\n",
    "    Dv = Dv.loc[~Dv.index.duplicated(keep='last')]\n",
    "    Dv = interpolate(Dv)\n",
    "    print(\"Dviento.csv index are unique:\",Dv.index.is_unique)\n",
    "\n",
    "    file = path + 'C02Humedad.csv'\n",
    "    Hr = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (%)'], dtype={'Valor (%)': float}, na_values=[''])\n",
    "    Hr = Hr.loc[~Hr.index.duplicated(keep='last')]\n",
    "    Hr = interpolate(Hr)\n",
    "    print(\"Humedad.csv index are unique:\",Hr.index.is_unique)\n",
    "\n",
    "    file = path + 'C02Presion.csv'\n",
    "    Ps = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (hPa)'], dtype={'Valor (hPa)': float}, na_values=[''])\n",
    "    Ps = Ps.loc[~Ps.index.duplicated(keep='last')]\n",
    "    Ps = interpolate(Ps)\n",
    "    print(\"Presion.csv index are unique:\",Ps.index.is_unique)\n",
    "\n",
    "    file = path + 'C02RSolar.csv'\n",
    "    Rs = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (W/m2)'], dtype={'Valor (W/m2)': float}, na_values=[''])\n",
    "    Rs = Rs.loc[~Rs.index.duplicated(keep='last')]\n",
    "    Rs = interpolate(Rs)\n",
    "    print(\"RSolar.csv index are unique:\",Rs.index.is_unique)\n",
    "\n",
    "    file = path + 'C02Temperatura.csv'\n",
    "    T = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (°C)'], dtype={'Valor (°C)': float}, na_values=[''])\n",
    "    T = T.loc[~T.index.duplicated(keep='last')]\n",
    "    T = interpolate(T)\n",
    "    print(\"Temperatura.csv index are unique:\",T.index.is_unique)\n",
    "\n",
    "    file = path + 'C02Vviento.csv'\n",
    "    Vv = pd.read_csv(file, index_col=0, usecols=['Fecha','Valor (m/s)'], dtype={'Valor (m/s)': float}, na_values=[''])\n",
    "    Vv = Vv.loc[~Vv.index.duplicated(keep='last')]\n",
    "    Vv = interpolate(Vv)\n",
    "    print(\"Vviento.csv index are unique:\",Vv.index.is_unique)\n",
    "\n",
    "    # concatenates all the variables trhough inner join\n",
    "    Dataset = pd.concat([Dv, Hr, Ps, Rs, T,Vv, Pp], axis=1 , join='inner')\n",
    "    Dataset['Date Time'] = pd.to_datetime(Dataset.index, format='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "    \n",
    "    print(\"Null values:\",Dataset.isnull().values.any())\n",
    "\n",
    "    \n",
    "    return (Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Convert the wind direction and velocity columns to a wind vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wind(Dataset):\n",
    "    wv = Dataset.pop('Valor (m/s)')\n",
    "\n",
    "    # Convert to radians.\n",
    "    wd_rad = Dataset.pop('Valor (°)')*np.pi / 180.0\n",
    "\n",
    "    # Calculate the wind x and y components.\n",
    "    Dataset['Wind X'] = wv*np.cos(wd_rad)\n",
    "    Dataset['Wind Y'] = wv*np.sin(wd_rad)\n",
    "\n",
    "    return (Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Use sin and cos to convert the time to clear \"Time of day\" and \"Time of year\" signals.\n",
    "\n",
    "Since weather data has daily and yearly periodicity, this gives the model access to the most important frequency features. So, determine which frequencies are important using an fft\n",
    "\n",
    "3.1. Plot the frequencies \n",
    "\n",
    "\n",
    "3.2. Convert using sin and cos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots the frequency of the data.**\n",
    "\n",
    "*Note the obvious peaks at frequencies near 1/30 days (one month)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fft(feature,col):\n",
    "    fft = tf.signal.rfft(feature)\n",
    "    f_per_dataset = np.arange(0, len(fft))\n",
    "\n",
    "    n_samples_h = len(feature)\n",
    "    hours_per_year = 24*365.2524\n",
    "    years_per_dataset = n_samples_h/(hours_per_year)\n",
    "\n",
    "    f_per_year = f_per_dataset/years_per_dataset\n",
    "    plt.step(f_per_year, np.abs(fft))\n",
    "    plt.xscale('log')\n",
    "    plt.title(col)\n",
    "    #plt.ylim([0, max(np.abs(fft))])\n",
    "    plt.ylim([0, 2.2e6])\n",
    "    plt.xlim([0.1, max(plt.xlim())])\n",
    "    _ = plt.xlabel('Frequency [Hz]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    plt.xticks([1, 30, 60, 365.2524,], labels=[r'$Year^{-1}$',r'$Month^{-1}$',r'$2-Month^{-1}$', r'$Day^{-1}$'],rotation = 45,fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def convert_time(Dataset):\n",
    "    date_time = pd.to_datetime(Dataset.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "    #in seconds\n",
    "    timestamp_s = date_time.map(datetime.datetime.timestamp)\n",
    "\n",
    "    day = 24*60*60\n",
    "    thirty_days =30*day\n",
    "    #year = (365.2425)*day\n",
    "\n",
    "    Dataset['Monthly sin'] = np.sin(timestamp_s * (2 * np.pi / thirty_days))\n",
    "    Dataset['Monthly cos'] = np.cos(timestamp_s * (2 * np.pi / thirty_days))\n",
    "\n",
    "    bi_month = 60*day\n",
    "    Dataset['Bi-monthly sin'] = np.sin(timestamp_s * (2 * np.pi / bi_month))\n",
    "    Dataset['Bi-monthly cos'] = np.cos(timestamp_s * (2 * np.pi / bi_month))\n",
    "\n",
    "    return (Dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar para Rumihurco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/juan/Desktop/TESIS/Codes/data/Rumihurco2021/'\n",
    "Dataset = read_csv(path)\n",
    "np.round(Dataset.describe(),1).to_csv(path+'Describe_Rumihurco_clean.csv')\n",
    "#for col in Dataset.columns:\n",
    "#    plot_fft(Dataset[col],col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = convert_time(Dataset)\n",
    "Dataset = convert_wind(Dataset)\n",
    "Dataset.to_csv(\"/home/juan/Desktop/TESIS/Codes/codesTesis/Paso1/Rumihurco.csv\")\n",
    "np.round(Dataset.describe(),1).to_csv(path+'Describe_Rumihurco_feature_eng.csv')\n",
    "Dataset.to_csv(path+'Rumihurco.csv')\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(Dataset.corr(),cmap=sns.color_palette(\"vlag\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetimos para para Rumipamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/juan/Desktop/TESIS/Codes/data/Rumipamba2021/'\n",
    "Dataset = read_csv(path)\n",
    "np.round(Dataset.describe(),1).to_csv(path+'Describe_Rumipamba_clean.csv')\n",
    "\n",
    "Dataset = convert_time(Dataset)\n",
    "Dataset = convert_wind(Dataset)\n",
    "Dataset.to_csv(\"/home/juan/Desktop/TESIS/Codes/codesTesis/Paso1/Rumipamba.csv\")\n",
    "np.round(Dataset.describe(),1).to_csv(path+'Describe_Rumipamba_feature_eng.csv')\n",
    "Dataset.to_csv(path+'Rumipamba.csv')\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(Dataset.corr(),cmap=sns.color_palette(\"vlag\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('DataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "594cd4c1775c7073e165f3e94c0806f65399c727a71c5868978d7fae6efe9fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
